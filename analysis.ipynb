{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "from scipy import stats\n",
    "import mne\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "import shap\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import logit\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "\n",
    "old = \"old_results_all.csv\"\n",
    "young = \"young_results_all.csv\"\n",
    "old_df = pd.read_csv(old)\n",
    "young_df = pd.read_csv(young)\n",
    "\n",
    "combined_df = pd.concat([old_df, young_df], ignore_index=True)\n",
    "\n",
    "old_male_id = old_df[old_df['group'].str.contains('Male')]['subject_id'].unique()\n",
    "old_female_id = old_df[old_df['group'].str.contains('Female')]['subject_id'].unique()\n",
    "\n",
    "print(f\"Number of old male participants: {len(old_male_id)}\")\n",
    "print(f\"Number of old female participants: {len(old_female_id)}\")\n",
    "\n",
    "\n",
    "young_male_id = combined_df[(combined_df['age_group'] == 'young') & (combined_df['group'].str.contains('Male'))]['subject_id'].unique()\n",
    "print(f\"Number of young male participants: {len(young_male_id)}\")\n",
    "\n",
    "young_female_id = combined_df[(combined_df['age_group'] == 'young') & (combined_df['group'].str.contains('Female'))]['subject_id'].unique()\n",
    "print(f\"Number of young female participants: {len(young_female_id)}\")\n",
    "\n",
    "young_male_subjects = np.random.choice(young_male_id, size=18, replace=False)\n",
    "young_female_subjects = np.random.choice(young_female_id, size=11, replace=False)\n",
    "\n",
    "selected_young_subjects = np.concatenate([young_male_subjects, young_female_subjects])\n",
    "\n",
    "\n",
    "# Create a new dataframe with the selected subjects both old and young\n",
    "selected_subjects = np.concatenate([old_male_id, old_female_id, selected_young_subjects])\n",
    "print(\"-\" * 100)\n",
    "print(f\"Selected subjects: {selected_subjects}\")\n",
    "print(len(selected_subjects))\n",
    "\n",
    "# Turn this into a dataframe\n",
    "new_df = combined_df[combined_df['subject_id'].isin(selected_subjects)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the power\n",
    "\n",
    "\n",
    "The following code implements a subject-specific normalization approach:\n",
    "\n",
    "1. **Create a working copy** of the original dataframe to preserve raw data\n",
    "2. **Iterate through each subject** to handle individual differences\n",
    "3. **Process each condition-band combination** separately for proper normalization context\n",
    "4. **Calculate normalization factor** as the sum of power values across all regions\n",
    "5. **Normalize region-specific power** by dividing by the total power\n",
    "\n",
    "This approach ensures that power comparisons between regions account for individual \n",
    "differences in overall signal strength while maintaining the relative distribution \n",
    "across brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_normalized = new_df.copy()\n",
    "for subject in new_df['subject_id'].unique():\n",
    "    subjectdf = new_df[new_df['subject_id'] == subject]\n",
    "\n",
    "    for condition in subjectdf['condition'].unique():\n",
    "        for band in subjectdf['band'].unique():\n",
    "            normalizs = subjectdf[(subjectdf['condition'] == condition) & (subjectdf['band'] == band)]['power'].sum()\n",
    "            for region in subjectdf['region'].unique():\n",
    "                power = subjectdf[(subjectdf['condition'] == condition) & (subjectdf['band'] == band) & (subjectdf['region'] == region)]['power'].values[0]\n",
    "                new_df_normalized.loc[(new_df_normalized['subject_id'] == subject) & (new_df_normalized['condition'] == condition) & (new_df_normalized['band'] == band) & (new_df_normalized['region'] == region),'normalized_power'] = power / normalizs\n",
    "\n",
    "new_df_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create a new column that combines age_group and condition for grouping\n",
    "new_df_normalized['group_condition'] = new_df_normalized['age_group'] + '_' + new_df_normalized['condition']\n",
    "\n",
    "# Define a custom palette\n",
    "palette = {\n",
    "    'young_EC': '#2b6d89',    # Darker blue for young EC\n",
    "    'young_EO': '#5dade2',    # Lighter blue for young EO\n",
    "    'older_EC': '#e67e22',    # Darker orange for older EC\n",
    "    'older_EO': '#f5b041'     # Lighter orange for older EO\n",
    "}\n",
    "\n",
    "# Create the grouped barplot\n",
    "ax = sns.barplot(\n",
    "    x='region', \n",
    "    y='normalized_power', \n",
    "    data=new_df_normalized, \n",
    "    hue='group_condition',\n",
    "    palette=palette, \n",
    "    errorbar=('ci', 95),\n",
    "    capsize=0.1,\n",
    "    width=0.8,\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "# Add grid and labels\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7, zorder=0)\n",
    "plt.title('Comparison of Normalized Power Between Age Groups and Conditions', fontsize=16, fontweight='bold', pad=15)\n",
    "plt.xlabel('Brain Region', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Normalized Power', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Format x-tick labels\n",
    "plt.xticks(fontweight='bold', rotation=45, ha='right')\n",
    "\n",
    "# Set y-axis limits\n",
    "plt.ylim([0.10, 0.50])\n",
    "plt.yticks(np.arange(0.10, 0.55, 0.05))\n",
    "\n",
    "# Format the legend\n",
    "plt.legend(\n",
    "    title='Age Group - Condition', \n",
    "    title_fontsize=12, \n",
    "    frameon=True, \n",
    "    facecolor='white', \n",
    "    edgecolor='gray',\n",
    "    bbox_to_anchor=(1.01, 0.5),\n",
    "    loc='center left'\n",
    ")\n",
    "\n",
    "# Hide top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an improved 2x2 facet grid\n",
    "g = sns.catplot(\n",
    "    data=new_df_normalized, \n",
    "    x='region',\n",
    "    y='normalized_power',\n",
    "    hue='band',\n",
    "    col='age_group',\n",
    "    row='condition',\n",
    "    kind='point',\n",
    "    dodge=True,\n",
    "    errorbar=('ci', 95),\n",
    "    palette=['#3b5998', '#20b2aa', '#66cdaa'],  # Better color contrast\n",
    "    height=5.5,\n",
    "    aspect=1.3,\n",
    "    markers=['o', 's', 'D'],\n",
    "    linestyles=['-', '--', '-.'],\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    legend_out=True\n",
    ")\n",
    "\n",
    "# Enhance labels and titles\n",
    "g.set_axis_labels(\"Brain Region\", \"Mean Normalized Power\", fontsize=12)\n",
    "g.set_titles(\"Age: {col_name} | Condition: {row_name}\", fontsize=13, fontweight='bold')\n",
    "g.set_xticklabels(fontsize=11, rotation=30, ha='right')  # Better readability\n",
    "\n",
    "# Improve y-axis appearance\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_ylim(0, 0.5)  # Consistent y-axis with some headroom\n",
    "    ax.tick_params(axis='y', labelsize=11)\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.7, color='#E0E0E0')\n",
    "    \n",
    "    # Add subtle background for better readability\n",
    "    ax.set_facecolor('#f9f9f9')\n",
    "    \n",
    "    # Add subtle spines\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#D0D0D0')\n",
    "        spine.set_linewidth(0.8)\n",
    "\n",
    "\n",
    "# Add a main title with better positioning\n",
    "plt.suptitle('Normalized EEG Power by Region, Band, Age Group and Condition', \n",
    "             y=1.05, fontsize=16, fontweight='bold')\n",
    "# After creating the plot, add these lines:\n",
    "regions = new_df_normalized['region'].unique()\n",
    "for i, ax in enumerate(g.axes.flat):\n",
    "    ax.set_xticks(range(len(regions)))\n",
    "    ax.set_xticklabels(regions, fontsize=11, rotation=30, ha='right')\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 grid for our four conditions (age_group × condition)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12), sharex=True, sharey=True)\n",
    "\n",
    "# Define age groups and conditions\n",
    "age_groups = ['older', 'young']\n",
    "conditions = ['EC', 'EO']\n",
    "\n",
    "# Get unique region names to ensure consistency\n",
    "regions = new_df_normalized['region'].unique()\n",
    "\n",
    "# Custom colormap with better perceptual properties\n",
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "# Loop through each combination and create a heatmap\n",
    "for i, condition in enumerate(conditions):\n",
    "    for j, age in enumerate(age_groups):\n",
    "        # Filter data for this subplot\n",
    "        subset = new_df_normalized[(new_df_normalized['age_group'] == age) & \n",
    "                                   (new_df_normalized['condition'] == condition)]\n",
    "        \n",
    "        # Create pivot table for this specific combination\n",
    "        pivot = subset.pivot_table(\n",
    "            index='region', \n",
    "            columns='band', \n",
    "            values='normalized_power',\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        \n",
    "        # Ensure pivot table has consistent row order matching regions list\n",
    "        pivot = pivot.reindex(regions)\n",
    "        \n",
    "        sns.heatmap(\n",
    "            pivot, \n",
    "            ax=axes[i, j],\n",
    "            cmap=cmap,\n",
    "            vmin=0.10,\n",
    "            vmax=0.45,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            linewidths=0.5,\n",
    "            cbar=False  # No colorbar on any subplot\n",
    "        )\n",
    "        \n",
    "        # Add titles\n",
    "        axes[i, j].set_title(f\"Age: {age} | Condition: {condition}\", \n",
    "                             fontsize=13, fontweight='bold')\n",
    "        \n",
    "        # Ensure region names are clearly displayed\n",
    "        axes[i, j].set_yticklabels(regions, fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set x/y labels only for outer subplots\n",
    "        if i == 1:\n",
    "            axes[i, j].set_xlabel('Frequency Band', fontsize=12)\n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel('Brain Region', fontsize=12)\n",
    "\n",
    "# Add a main title\n",
    "plt.suptitle('EEG Power Matrix by Region, Band, Age Group and Condition', \n",
    "             y=0.98, fontsize=16, fontweight='bold')\n",
    "\n",
    "# Add a single colorbar for the entire figure\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # [x, y, width, height]\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(0.15, 0.45))\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "cbar.set_label('Mean Normalized Power', fontsize=12)\n",
    "\n",
    "# Adjust spacing\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 0.95])  # Make room for colorbar\n",
    "plt.subplots_adjust(top=0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Two-way mixed ANOVA for each brain region\n",
    "# Analyze differences between age groups, conditions, and their interaction\n",
    "\n",
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to perform two-way mixed ANOVA for each region\n",
    "def region_anova(data, region_name):\n",
    "    # Filter data for the specific region\n",
    "    region_data = data[data['region'] == region_name].copy()\n",
    "    \n",
    "    # Reshape data for ANOVA\n",
    "    aov = pg.mixed_anova(\n",
    "        dv='normalized_power',         # Dependent variable\n",
    "        within='condition',            # Within-subjects factor\n",
    "        between='age_group',           # Between-subjects factor\n",
    "        subject='subject_id',          # Subject identifier\n",
    "        data=region_data\n",
    "    )\n",
    "    \n",
    "    # Add region information to the results\n",
    "    aov['brain_region'] = region_name\n",
    "    \n",
    "    return aov\n",
    "\n",
    "# Run ANOVA for each region\n",
    "regions = new_df_normalized['region'].unique()\n",
    "anova_results = pd.DataFrame()\n",
    "\n",
    "for region in regions:\n",
    "    result = region_anova(new_df_normalized, region)\n",
    "    anova_results = pd.concat([anova_results, result], ignore_index=True)\n",
    "\n",
    "# Display ANOVA results with formatted p-values and interpretations\n",
    "anova_summary = anova_results.copy()\n",
    "anova_summary['p-value'] = anova_summary['p-unc'].apply(lambda p: f\"{p:.4f}\" + (\"*\" if p < 0.05 else \"\"))\n",
    "anova_summary['significance'] = anova_summary['p-unc'].apply(lambda p: \"Significant\" if p < 0.05 else \"Not significant\")\n",
    "anova_summary = anova_summary[['brain_region', 'Source', 'F', 'p-value', 'significance']]\n",
    "\n",
    "print(\"Two-way mixed ANOVA results for each brain region:\")\n",
    "print(anova_summary)\n",
    "print(\"\\n* = p < 0.05\")\n",
    "\n",
    "# 2. Post-hoc tests for significant interactions or main effects\n",
    "def posthoc_tests(data):\n",
    "    posthoc_results = pd.DataFrame()\n",
    "    regions = data['region'].unique()\n",
    "    \n",
    "    for region in regions:\n",
    "        region_data = data[data['region'] == region].copy()\n",
    "        \n",
    "        # Post-hoc for age group differences (within each condition)\n",
    "        for condition in ['EC', 'EO']:\n",
    "            condition_data = region_data[region_data['condition'] == condition]\n",
    "            \n",
    "            # Compare age groups within condition\n",
    "            ttest = pg.ttest(\n",
    "                condition_data[condition_data['age_group'] == 'young']['normalized_power'],\n",
    "                condition_data[condition_data['age_group'] == 'older']['normalized_power'],\n",
    "                paired=False\n",
    "            )\n",
    "            \n",
    "            ttest['brain_region'] = region\n",
    "            ttest['comparison'] = f\"young vs older ({condition})\"\n",
    "            posthoc_results = pd.concat([posthoc_results, ttest], ignore_index=True)\n",
    "        \n",
    "        # Post-hoc for condition differences (within each age group)\n",
    "        for age in ['young', 'older']:\n",
    "            age_data = region_data[region_data['age_group'] == age]\n",
    "            \n",
    "            # Compare conditions within age group\n",
    "            ttest = pg.ttest(\n",
    "                age_data[age_data['condition'] == 'EC']['normalized_power'],\n",
    "                age_data[age_data['condition'] == 'EO']['normalized_power'],\n",
    "                paired=True  # Paired because same subjects did both conditions\n",
    "            )\n",
    "            \n",
    "            ttest['brain_region'] = region\n",
    "            ttest['comparison'] = f\"EC vs EO ({age})\"\n",
    "            posthoc_results = pd.concat([posthoc_results, ttest], ignore_index=True)\n",
    "    \n",
    "    return posthoc_results\n",
    "\n",
    "# Run post-hoc tests\n",
    "posthoc_results = posthoc_tests(new_df_normalized)\n",
    "\n",
    "# Format post-hoc results for display\n",
    "posthoc_summary = posthoc_results.copy()\n",
    "posthoc_summary['p-value'] = posthoc_summary['p-val'].apply(lambda p: f\"{p:.4f}\" + (\"*\" if p < 0.05 else \"\"))\n",
    "posthoc_summary['cohen-d'] = posthoc_summary['cohen-d'].apply(lambda d: f\"{d:.3f}\")\n",
    "posthoc_summary = posthoc_summary[['brain_region', 'comparison', 'cohen-d', 'p-value']]\n",
    "\n",
    "print(\"\\nPost-hoc t-tests for significant effects:\")\n",
    "print(posthoc_summary)\n",
    "print(\"\\n* = p < 0.05\")\n",
    "\n",
    "# 3. Frequency band analysis with mixed ANOVA for each band\n",
    "def band_anova(data, band_name):\n",
    "    # Filter data for specific band\n",
    "    band_data = data[data['band'] == band_name].copy()\n",
    "    \n",
    "    # Perform ANOVA\n",
    "    aov = pg.mixed_anova(\n",
    "        dv='normalized_power',\n",
    "        within='condition',\n",
    "        between='age_group',\n",
    "        subject='subject_id',\n",
    "        data=band_data\n",
    "    )\n",
    "    \n",
    "    aov['frequency_band'] = band_name\n",
    "    return aov\n",
    "\n",
    "# Run ANOVA for each frequency band\n",
    "bands = new_df_normalized['band'].unique()\n",
    "band_anova_results = pd.DataFrame()\n",
    "\n",
    "for band in bands:\n",
    "    result = band_anova(new_df_normalized, band)\n",
    "    band_anova_results = pd.concat([band_anova_results, result], ignore_index=True)\n",
    "\n",
    "# Format band ANOVA results\n",
    "band_summary = band_anova_results.copy()\n",
    "band_summary['p-value'] = band_summary['p-unc'].apply(lambda p: f\"{p:.4f}\" + (\"*\" if p < 0.05 else \"\"))\n",
    "band_summary['significance'] = band_summary['p-unc'].apply(lambda p: \"Significant\" if p < 0.05 else \"Not significant\")\n",
    "band_summary = band_summary[['frequency_band', 'Source', 'F', 'p-value', 'significance']]\n",
    "\n",
    "print(\"\\nTwo-way mixed ANOVA results for each frequency band:\")\n",
    "print(band_summary)\n",
    "print(\"\\n* = p < 0.05\")\n",
    "\n",
    "# 4. Three-way mixed ANOVA (region × age group × condition)\n",
    "# This tests if the pattern of age and condition effects differs across regions\n",
    "def three_way_anova(data):\n",
    "    # Create a long-format DataFrame suitable for three-way ANOVA\n",
    "    # We'll need to reshape the data to have 'region' as a within-subject factor\n",
    "    subjects = data['subject_id'].unique()\n",
    "    regions = data['region'].unique()\n",
    "    long_data = []\n",
    "    \n",
    "    for subject in subjects:\n",
    "        subject_data = data[data['subject_id'] == subject]\n",
    "        for condition in ['EC', 'EO']:\n",
    "            condition_data = subject_data[subject_data['condition'] == condition]\n",
    "            if len(condition_data) < len(regions):  # Skip if data incomplete\n",
    "                continue\n",
    "                \n",
    "            age_group = condition_data['age_group'].iloc[0]\n",
    "            \n",
    "            for region in regions:\n",
    "                region_data = condition_data[condition_data['region'] == region]\n",
    "                if len(region_data) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                for band in bands:\n",
    "                    band_data = region_data[region_data['band'] == band]\n",
    "                    if len(band_data) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    power = band_data['normalized_power'].iloc[0]\n",
    "                    \n",
    "                    long_data.append({\n",
    "                        'subject_id': subject,\n",
    "                        'age_group': age_group,\n",
    "                        'condition': condition,\n",
    "                        'region': region,\n",
    "                        'band': band,\n",
    "                        'normalized_power': power\n",
    "                    })\n",
    "    \n",
    "    long_df = pd.DataFrame(long_data)\n",
    "    \n",
    "    # Perform three-way mixed ANOVA for each frequency band\n",
    "    three_way_results = pd.DataFrame()\n",
    "    \n",
    "    for band in bands:\n",
    "        band_data = long_df[long_df['band'] == band].copy()\n",
    "        \n",
    "        # Perform ANOVA with region as within-subject factor\n",
    "        try:\n",
    "            aov = pg.mixed_anova(\n",
    "                dv='normalized_power',\n",
    "                within=['condition', 'region'],  # Two within-subject factors\n",
    "                between='age_group',             # Between-subjects factor\n",
    "                subject='subject_id',\n",
    "                data=band_data\n",
    "            )\n",
    "            \n",
    "            aov['frequency_band'] = band\n",
    "            three_way_results = pd.concat([three_way_results, aov], ignore_index=True)\n",
    "        except:\n",
    "            print(f\"Could not perform full three-way ANOVA for {band} band.\")\n",
    "            # Use simplified approach with interaction terms\n",
    "            simplified_aov = pg.rm_anova(\n",
    "                dv='normalized_power',\n",
    "                within=['condition', 'region'],\n",
    "                subject='subject_id',\n",
    "                data=band_data,\n",
    "                detailed=True\n",
    "            )\n",
    "            simplified_aov['frequency_band'] = band\n",
    "            three_way_results = pd.concat([three_way_results, simplified_aov], ignore_index=True)\n",
    "    \n",
    "    return three_way_results\n",
    "\n",
    "# Run three-way ANOVA\n",
    "try:\n",
    "    three_way_results = three_way_anova(new_df_normalized)\n",
    "    \n",
    "    # Format results\n",
    "    three_way_summary = three_way_results.copy()\n",
    "    three_way_summary['p-value'] = three_way_summary['p-unc'].apply(lambda p: f\"{p:.4f}\" + (\"*\" if p < 0.05 else \"\"))\n",
    "    three_way_summary['significance'] = three_way_summary['p-unc'].apply(lambda p: \"Significant\" if p < 0.05 else \"Not significant\")\n",
    "    three_way_summary = three_way_summary[['frequency_band', 'Source', 'F', 'p-value', 'significance']]\n",
    "    \n",
    "    print(\"\\nThree-way mixed ANOVA (region × age group × condition):\")\n",
    "    print(three_way_summary)\n",
    "except Exception as e:\n",
    "    print(\"\\nCould not perform complete three-way ANOVA, using alternative approach...\")\n",
    "    \n",
    "    # Alternative: region-wise test of condition × age_group interaction\n",
    "    region_interaction_results = pd.DataFrame()\n",
    "    \n",
    "    for region in regions:\n",
    "        for band in bands:\n",
    "            region_band_data = new_df_normalized[(new_df_normalized['region'] == region) & \n",
    "                                                (new_df_normalized['band'] == band)]\n",
    "            \n",
    "            if len(region_band_data) > 0:\n",
    "                model = pg.anova(\n",
    "                    dv='normalized_power',\n",
    "                    between=['age_group', 'condition'],\n",
    "                    data=region_band_data,\n",
    "                    detailed=True\n",
    "                )\n",
    "                \n",
    "                model['region'] = region\n",
    "                model['band'] = band\n",
    "                region_interaction_results = pd.concat([region_interaction_results, model], ignore_index=True)\n",
    "    \n",
    "    # Show interaction results\n",
    "    interaction_summary = region_interaction_results[region_interaction_results['Source'] == 'age_group * condition'].copy()\n",
    "    interaction_summary['p-value'] = interaction_summary['p-unc'].apply(lambda p: f\"{p:.4f}\" + (\"*\" if p < 0.05 else \"\"))\n",
    "    interaction_summary = interaction_summary[['region', 'band', 'F', 'p-value']]\n",
    "    \n",
    "    print(\"\\nAge Group × Condition interaction for each region and band:\")\n",
    "    print(interaction_summary)\n",
    "\n",
    "# 5. Effect size analysis for age differences by region\n",
    "def calculate_effect_sizes(data):\n",
    "    effect_sizes = pd.DataFrame()\n",
    "    \n",
    "    for region in regions:\n",
    "        region_data = data[data['region'] == region]\n",
    "        \n",
    "        for band in bands:\n",
    "            band_data = region_data[region_data['band'] == band]\n",
    "            \n",
    "            for condition in ['EC', 'EO']:\n",
    "                condition_data = band_data[band_data['condition'] == condition]\n",
    "                \n",
    "                young_data = condition_data[condition_data['age_group'] == 'young']['normalized_power']\n",
    "                older_data = condition_data[condition_data['age_group'] == 'older']['normalized_power']\n",
    "                \n",
    "                if len(young_data) > 0 and len(older_data) > 0:\n",
    "                    # Calculate Cohen's d effect size\n",
    "                    effect_size = pg.compute_effsize(\n",
    "                        young_data, \n",
    "                        older_data,\n",
    "                        paired=False,\n",
    "                        eftype='cohen'\n",
    "                    )\n",
    "                    \n",
    "                    effect_sizes = pd.concat([effect_sizes, pd.DataFrame({\n",
    "                        'region': [region],\n",
    "                        'band': [band],\n",
    "                        'condition': [condition],\n",
    "                        'effect_size': [effect_size],\n",
    "                        'magnitude': [interpret_effect_size(effect_size)]\n",
    "                    })], ignore_index=True)\n",
    "    \n",
    "    return effect_sizes\n",
    "\n",
    "def interpret_effect_size(d):\n",
    "    \"\"\"Interpret Cohen's d effect size magnitude\"\"\"\n",
    "    if abs(d) < 0.2:\n",
    "        return \"Negligible\"\n",
    "    elif abs(d) < 0.5:\n",
    "        return \"Small\"\n",
    "    elif abs(d) < 0.8:\n",
    "        return \"Medium\" \n",
    "    else:\n",
    "        return \"Large\"\n",
    "\n",
    "# Calculate effect sizes\n",
    "effect_sizes = calculate_effect_sizes(new_df_normalized)\n",
    "\n",
    "# Format effect size results\n",
    "effect_sizes['effect_size'] = effect_sizes['effect_size'].apply(lambda d: f\"{d:.3f}\")\n",
    "\n",
    "print(\"\\nEffect sizes (Cohen's d) for age group differences by region, band and condition:\")\n",
    "print(effect_sizes[['region', 'band', 'condition', 'effect_size', 'magnitude']])\n",
    "\n",
    "# 6. Correlation analysis between regions for each age group and condition\n",
    "def correlation_analysis(data):\n",
    "    corr_results = []\n",
    "    \n",
    "    for age in ['young', 'older']:\n",
    "        for condition in ['EC', 'EO']:\n",
    "            # Filter data for this age group and condition\n",
    "            filtered_data = data[(data['age_group'] == age) & \n",
    "                               (data['condition'] == condition)]\n",
    "            \n",
    "            # Calculate correlations between regions for each band\n",
    "            for band in bands:\n",
    "                band_data = filtered_data[filtered_data['band'] == band]\n",
    "                \n",
    "                # Create pivot table with regions as columns\n",
    "                pivot_data = band_data.pivot_table(\n",
    "                    index='subject_id',\n",
    "                    columns='region',\n",
    "                    values='normalized_power',\n",
    "                    aggfunc='mean'\n",
    "                )\n",
    "                \n",
    "                # Calculate correlation matrix\n",
    "                correlation_matrix = pivot_data.corr(method='pearson')\n",
    "                \n",
    "                # Extract non-redundant correlations (upper triangle)\n",
    "                for i, region1 in enumerate(regions[:-1]):\n",
    "                    for region2 in regions[i+1:]:\n",
    "                        corr_coef = correlation_matrix.loc[region1, region2]\n",
    "                        \n",
    "                        # Calculate significance\n",
    "                        r, p_value = stats.pearsonr(\n",
    "                            pivot_data[region1].dropna(),\n",
    "                            pivot_data[region2].dropna()\n",
    "                        )\n",
    "                        \n",
    "                        corr_results.append({\n",
    "                            'age_group': age,\n",
    "                            'condition': condition,\n",
    "                            'band': band,\n",
    "                            'region1': region1,\n",
    "                            'region2': region2,\n",
    "                            'correlation': corr_coef,\n",
    "                            'p_value': p_value\n",
    "                        })\n",
    "    \n",
    "    return pd.DataFrame(corr_results)\n",
    "\n",
    "# Run correlation analysis\n",
    "correlation_results = correlation_analysis(new_df_normalized)\n",
    "\n",
    "# Format correlation results\n",
    "correlation_summary = correlation_results.copy()\n",
    "correlation_summary['correlation'] = correlation_summary['correlation'].apply(lambda r: f\"{r:.3f}\")\n",
    "correlation_summary['p-value'] = correlation_summary['p_value'].apply(lambda p: f\"{p:.4f}\" + (\"*\" if p < 0.05 else \"\"))\n",
    "correlation_summary = correlation_summary[['age_group', 'condition', 'band', 'region1', 'region2', 'correlation', 'p-value']]\n",
    "\n",
    "print(\"\\nCorrelations between brain regions for each age group and condition:\")\n",
    "# Show only significant correlations\n",
    "significant_corrs = correlation_summary[correlation_summary['p-value'].str.contains('\\*')]\n",
    "print(significant_corrs)\n",
    "print(\"\\n* = p < 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dataset **Long** -> **Wide**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok So given the current format of my data set I will be turning my dataframe from long to wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_normalized['feature_name'] = new_df_normalized['condition'] + '_' + new_df_normalized['band'] + '_' + new_df_normalized['region'] # a new column that contains the feature name\n",
    "print(new_df_normalized['feature_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_normalized\n",
    "new_df_normalized = new_df_normalized.drop('power', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df = new_df_normalized.pivot_table(\n",
    "    index = \"subject_id\", # unique identifier for each subject\n",
    "    columns= 'feature_name', # the feature name\n",
    "    values = 'normalized_power', # the values to be pivoted\n",
    "    aggfunc = 'first' # how to handle duplicate values\n",
    ")\n",
    "wide_df = wide_df.reset_index()\n",
    "wide_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Demographics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = new_df_normalized[['subject_id', 'age_group']].drop_duplicates()\n",
    "value_counts = age_group['age_group'].value_counts()\n",
    "print(f\"Age group info: \")\n",
    "print(value_counts)\n",
    "gender_info = new_df_normalized[['subject_id', 'group']].drop_duplicates()\n",
    "print(f\"Gender info: \")\n",
    "gender_info['gender'] = gender_info['group'].apply(\n",
    "    lambda x: 'Female' if 'Female' in x else 'Male')\n",
    "gender_value_counts = gender_info['gender'].value_counts()\n",
    "print(gender_value_counts)\n",
    "\n",
    "wide_df = wide_df.merge(age_group, on='subject_id')\n",
    "wide_df = wide_df.merge(gender_info[['subject_id', 'gender']], on='subject_id')\n",
    "\n",
    "wide_df.head(5)\n",
    "\n",
    "# List the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.shape\n",
    "\n",
    "for col in wide_df.columns:\n",
    "    print(col)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X = wide_df.drop(columns=['subject_id', 'age_group', 'gender'])\n",
    "y = wide_df['age_group']\n",
    "y_binary = (y == 'older').astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.25, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} subjects\")\n",
    "print(f\"Testing set: {X_test.shape[0]} subjects\")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    k_best = trial.suggest_int('k_best', 10, min(50, X_train.shape[1]))\n",
    "    \n",
    "    # Random Forest hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    # Create pipeline with trial parameters\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SelectKBest(f_classif, k=k_best)),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Use cross-validation to evaluate the model\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "# Create and run the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, n_jobs=-1)  # Adjust number of trials as needed\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  ROC AUC: {trial.value:.4f}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Create final model with best parameters\n",
    "best_k = trial.params['k_best']\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('selector', SelectKBest(f_classif, k=best_k)),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=trial.params['n_estimators'],\n",
    "        max_depth=trial.params['max_depth'],\n",
    "        min_samples_split=trial.params['min_samples_split'],\n",
    "        min_samples_leaf=trial.params['min_samples_leaf'],\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train on the full training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "# To see which features were selected\n",
    "selected_features = X.columns[pipeline.named_steps['selector'].get_support()]\n",
    "print(f\"\\nSelected features ({len(selected_features)}):\")\n",
    "print(selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Metrics Above\n",
    "\n",
    "**Accuracy** How many times the model correctly classified of all samples\n",
    "\n",
    "**F1** This is the harmonic mean between the precision and recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically a 88 percent performance on 5 fold could be very accaptable but I dont know for a sample size as small as this one  will need to read more about this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Cross-validation results\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, X, y_binary, cv=cv, scoring='accuracy')\n",
    "print(f\"\\nCross-validation accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "# Visualize cross-validation performance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, 6), cv_scores, color='skyblue', edgecolor='black')\n",
    "plt.axhline(cv_scores.mean(), color='red', linestyle='--', label=f'Mean: {cv_scores.mean():.3f}')\n",
    "plt.xlabel('Fold', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.title('5-Fold Cross-Validation Performance', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = pipeline.named_steps['selector'].get_support(indices=True)\n",
    "selected_features = X.columns[selected_indices].tolist()\n",
    "importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': importances\n",
    "})\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=False)\n",
    "print(\"Top 10 most important features:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# Get feature importance from Random Forest\n",
    "selected_X_train = pipeline.named_steps['selector'].transform(X_train)\n",
    "rf_classifier = pipeline.named_steps['classifier']\n",
    "# Map importances back to original feature names\n",
    "importances = pd.Series(\n",
    "    rf_classifier.feature_importances_,\n",
    "    index=selected_features\n",
    ")\n",
    "\n",
    "# Sort and visualize top features\n",
    "plt.figure(figsize=(10, 8))\n",
    "importances = importances.sort_values(ascending=False)\n",
    "ax = importances[:15].plot(kind='barh')\n",
    "ax.invert_yaxis()  # Display with highest importance at the top\n",
    "plt.title('Top 15 Features Importance for Age Group Prediction')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance the statistical testing function\n",
    "def add_enhanced_statistical_testing(features, df):\n",
    "    results = []\n",
    "    \n",
    "    for feature in features:\n",
    "        parts = feature.split('_')\n",
    "        condition = parts[0]\n",
    "        band = parts[1]\n",
    "        region = '_'.join(parts[2:])\n",
    "        \n",
    "        # Get values for each group\n",
    "        young_values = df[(df['age_group'] == 'young') & \n",
    "                         (df['condition'] == condition) & \n",
    "                         (df['band'] == band) & \n",
    "                         (df['region'] == region)]['normalized_power']\n",
    "        \n",
    "        older_values = df[(df['age_group'] == 'older') & \n",
    "                         (df['condition'] == condition) & \n",
    "                         (df['band'] == band) & \n",
    "                         (df['region'] == region)]['normalized_power']\n",
    "        \n",
    "        # Calculate means for both groups\n",
    "        young_mean = young_values.mean()\n",
    "        older_mean = older_values.mean()\n",
    "        \n",
    "        # Calculate percent difference\n",
    "        percent_diff = ((older_mean - young_mean) / young_mean) * 100\n",
    "        \n",
    "        # Run t-test\n",
    "        t_stat, p_value = stats.ttest_ind(older_values, young_values, equal_var=False)\n",
    "        \n",
    "        # Determine which group has higher power\n",
    "        direction = \"Older > Young\" if t_stat > 0 else \"Young > Older\"\n",
    "        \n",
    "        # Add to results\n",
    "        results.append({\n",
    "            'Feature': feature,\n",
    "            'Condition': condition,\n",
    "            'Band': band,\n",
    "            'Region': region,\n",
    "            'Young Mean': young_mean,\n",
    "            'Older Mean': older_mean,\n",
    "            'Percent Diff': percent_diff,\n",
    "            't-statistic': t_stat,\n",
    "            'p-value': p_value,\n",
    "            'Direction': direction,\n",
    "            'Significant': p_value < 0.05,\n",
    "            'Significance': '***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'ns'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run enhanced statistical testing\n",
    "enhanced_stats = add_enhanced_statistical_testing(feature_importances['Feature'], new_df_normalized)\n",
    "\n",
    "# Group by region and sort by absolute t-statistic for better interpretation\n",
    "enhanced_stats['Abs_t'] = abs(enhanced_stats['t-statistic'])\n",
    "enhanced_stats_sorted = enhanced_stats.sort_values(['Region', 'Abs_t'], ascending=[True, False])\n",
    "\n",
    "# Format p-values\n",
    "enhanced_stats_sorted['p-value_fmt'] = enhanced_stats_sorted['p-value'].apply(\n",
    "    lambda x: f\"{x:.3e}\" if x < 0.001 else f\"{x:.3f}\")\n",
    "\n",
    "# Create a more readable display function\n",
    "def display_region_stats(stats_df):\n",
    "    # Define ANSI color codes for terminal output\n",
    "    BOLD = '\\033[1m'\n",
    "    GREEN = '\\033[92m'\n",
    "    RED = '\\033[91m'\n",
    "    BLUE = '\\033[94m'\n",
    "    END = '\\033[0m'\n",
    "    \n",
    "    # List of regions in the order we want to display (posterior to anterior, following PASA)\n",
    "    regions = ['occipital', 'parietal', 'temporal', 'frontal']\n",
    "    \n",
    "    # Print header\n",
    "    print(f\"\\n{BOLD}Statistical Analysis of EEG Power Differences Between Age Groups{END}\")\n",
    "    for region in regions:\n",
    "        region_data = stats_df[stats_df['Region'] == region].copy()\n",
    "        if len(region_data) > 0:\n",
    "            # Print region header with posterior/anterior classification\n",
    "            region_type = \"POSTERIOR\" if region in ['occipital', 'parietal'] else \"ANTERIOR\"\n",
    "            print(f\"\\n{BOLD}{BLUE}Region: {region.upper()} ({region_type}){END}\")\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            # Print column headers\n",
    "            print(f\"{BOLD}{'Feature':<20} {'Band':<10} {'Condition':<10} {'Young':<10} {'Older':<10} {'%Diff':<10} {'t-stat':<10} {'p-value':<15} {'Significance':<15}{END}\")\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            # Print each row\n",
    "            for _, row in region_data.iterrows():\n",
    "                # Color code based on direction (green for older>young, red for young>older)\n",
    "                color = GREEN if row['Direction'] == 'Older > Young' else RED\n",
    "                sign = row['Significance']\n",
    "                \n",
    "                print(f\"{row['Feature']:<20} {row['Band']:<10} {row['Condition']:<10} \"\n",
    "                      f\"{row['Young Mean']:.3f}    {row['Older Mean']:.3f}    \"\n",
    "                      f\"{color}{row['Percent Diff']:+.1f}%{END}    \"\n",
    "                      f\"{row['t-statistic']:+.2f}    {row['p-value_fmt']:<15} \"\n",
    "                      f\"{color}{sign}{END}\")\n",
    "    \n",
    "    # Print summary relevant to the PASA model\n",
    "    print(f\"\\n{BOLD}Summary of Findings Relevant to PASA Model:{END}\")\n",
    "    posterior_regions = stats_df[stats_df['Region'].isin(['occipital', 'parietal'])]\n",
    "    anterior_regions = stats_df[stats_df['Region'].isin(['temporal', 'frontal'])]\n",
    "    \n",
    "    posterior_direction = posterior_regions['t-statistic'].mean() < 0\n",
    "    anterior_direction = anterior_regions['t-statistic'].mean() > 0\n",
    "    \n",
    "    pasa_support = posterior_direction and anterior_direction\n",
    "    \n",
    "    print(f\"Posterior regions (occipital, parietal): \"\n",
    "          f\"{'Young > Older' if posterior_direction else 'Older > Young'} \"\n",
    "          f\"(Mean t-stat: {posterior_regions['t-statistic'].mean():.2f})\")\n",
    "    \n",
    "    print(f\"Anterior regions (temporal, frontal): \"\n",
    "          f\"{'Older > Young' if anterior_direction else 'Young > Older'} \"\n",
    "          f\"(Mean t-stat: {anterior_regions['t-statistic'].mean():.2f})\")\n",
    "    \n",
    "\n",
    "# Display the enhanced statistics\n",
    "display_region_stats(enhanced_stats_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region-wise feature importance analysis\n",
    "region_importances = {}\n",
    "\n",
    "for feature, importance in zip(selected_features, rf_classifier.feature_importances_):\n",
    "    # Extract region from feature name (assuming format like 'EC_alpha_occipital')\n",
    "    region = feature.split('_')[-1]\n",
    "    \n",
    "    if region not in region_importances:\n",
    "        region_importances[region] = 0\n",
    "    region_importances[region] += importance\n",
    "\n",
    "# Plot region-wise importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "regions = list(region_importances.keys())\n",
    "importances = list(region_importances.values())\n",
    "colors = ['#3498db', '#e67e22', '#2ecc71', '#e74c3c']  # Same colors as before\n",
    "\n",
    "plt.bar(regions, importances, color=colors, edgecolor='black')\n",
    "plt.xlabel('Brain Region', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Cumulative Importance', fontsize=12, fontweight='bold')\n",
    "plt.title('Brain Region Contribution to Age Classification', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=0, fontweight='bold')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trento1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
